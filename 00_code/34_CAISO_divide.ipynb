{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-11T19:30:17.131119Z",
     "start_time": "2025-10-11T19:30:17.006283Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ===================== Configuration Area =====================\n",
    "# Input File Paths\n",
    "PATH_INVEST = \"./load and costs/CAISO/CAISO_cost.xlsx\"         # Table 1: Year, Cost\n",
    "PATH_GROWTH = \"./load and costs/CAISO/22_load_compare.xlsx\"    # Table 2: One sheet per region\n",
    "PATH_SPLIT  = \"./rider/CAISO/00_CAISO_share.xlsx\"              # Table 3: One sheet per region (contains RU, DC rows)\n",
    "\n",
    "# Table 1 Column Names\n",
    "COL_YEAR_1  = \"Year\"\n",
    "COL_COST_1  = \"Cost\"\n",
    "\n",
    "# Table 2 Column Names (in each region's sheet)\n",
    "COL_YEAR_2      = None   # If None, the program attempts to auto-identify the first column as Year\n",
    "COL_RES_DELTA   = [\"RES DELTA\", \"Residential Delta\", \"RES_DELTA\", \"RES\"]  # Residential growth (may be negative; zeroed out after averaging)\n",
    "COL_DC_DELTA    = [\"DC DELTA\", \"DC delta\", \"DC_DELTA\", \"DC\"]              # DC growth (4th column)\n",
    "\n",
    "# Special Row Handling (Table 2)\n",
    "YEARS_TO_DROP = [2019]           # First row is 2019, needs to be skipped\n",
    "DROP_ROWS_IF_ALL_ZERO = True     # Note: This version drops rows ONLY if they are all zero AFTER averaging\n",
    "\n",
    "# Keywords to identify RU/DC rows in Table 3 (case-insensitive, fuzzy match)\n",
    "KW_RU = [\"RU\", \"Residential\"]\n",
    "KW_DC = [\"DC\"]\n",
    "\n",
    "# Lookahead Window\n",
    "LOOKAHEAD_YEARS = 5              # Set to 5 for a 5-year forward rolling mean\n",
    "\n",
    "# Output Directory\n",
    "OUTDIR = Path(\"./rider/CAISO/\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "# ===================================================\n",
    "\n",
    "def _find_first_existing_col(df, candidates):\n",
    "    if candidates is None:\n",
    "        return df.columns[0]\n",
    "    if isinstance(candidates, str):\n",
    "        return candidates if candidates in df.columns else None\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _normalize_year_series(s):\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "def read_table1(path):\n",
    "    df = pd.read_excel(path)\n",
    "    ycol = COL_YEAR_1 if COL_YEAR_1 in df.columns else df.columns[0]\n",
    "    ccol = COL_COST_1 if COL_COST_1 in df.columns else df.columns[1]\n",
    "    df = df.rename(columns={ycol: \"Year\", ccol: \"TotalCost\"})\n",
    "    df[\"Year\"] = _normalize_year_series(df[\"Year\"])\n",
    "    df = df.dropna(subset=[\"Year\", \"TotalCost\"]).copy()\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "    return df[[\"Year\", \"TotalCost\"]]\n",
    "\n",
    "def read_table2_all_regions_raw(path):\n",
    "    \"\"\"\n",
    "    Read Table 2 as a long format (Region, Year, RES_raw, DC_raw).\n",
    "    **No sign adjustment or zero-row dropping here** (to avoid affecting forward averaging).\n",
    "    \"\"\"\n",
    "    xl = pd.ExcelFile(path)\n",
    "    out = []\n",
    "    for sheet in xl.sheet_names:\n",
    "        df = xl.parse(sheet)\n",
    "\n",
    "        # Year Column\n",
    "        ycol = _find_first_existing_col(df, COL_YEAR_2) or df.columns[0]\n",
    "        df = df.rename(columns={ycol: \"Year\"})\n",
    "        df[\"Year\"] = _normalize_year_series(df[\"Year\"])\n",
    "        df = df.dropna(subset=[\"Year\"]).copy()\n",
    "        df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "\n",
    "        # Skip specified years (e.g., 2019)\n",
    "        if YEARS_TO_DROP:\n",
    "            df = df[~df[\"Year\"].isin(YEARS_TO_DROP)]\n",
    "\n",
    "        # Capture raw RES / DC columns\n",
    "        res_col = _find_first_existing_col(df, COL_RES_DELTA)\n",
    "        dc_col  = _find_first_existing_col(df, COL_DC_DELTA)\n",
    "        if res_col is None or dc_col is None:\n",
    "            raise ValueError(f\"[{sheet}] RES/DC columns not found, please check column names. Existing columns: {df.columns.tolist()}\")\n",
    "\n",
    "        part = pd.DataFrame({\n",
    "            \"Region\": sheet,\n",
    "            \"Year\": df[\"Year\"].values,\n",
    "            \"RES_raw\": pd.to_numeric(df[res_col], errors=\"coerce\").fillna(0.0).values,\n",
    "            \"DC_raw\":  pd.to_numeric(df[dc_col],  errors=\"coerce\").fillna(0.0).values\n",
    "        })\n",
    "        out.append(part)\n",
    "\n",
    "    full = pd.concat(out, ignore_index=True)\n",
    "    return full  # cols: Region, Year, RES_raw, DC_raw\n",
    "\n",
    "def read_table3_splits(path):\n",
    "    xl = pd.ExcelFile(path)\n",
    "    long_rows = []\n",
    "\n",
    "    def pick_row_index(idx):\n",
    "        idx_lower = [str(x).lower() for x in idx]\n",
    "        def _find(kw_list):\n",
    "            for kw in kw_list:\n",
    "                kw_l = kw.lower()\n",
    "                for i, name in enumerate(idx_lower):\n",
    "                    if kw_l in name:\n",
    "                        return i\n",
    "            return None\n",
    "        return _find(KW_RU), _find(KW_DC)\n",
    "\n",
    "    for sheet in xl.sheet_names:\n",
    "        df = xl.parse(sheet)\n",
    "        df = df.rename(columns={df.columns[0]: \"index\"})\n",
    "        df = df.set_index(\"index\")\n",
    "\n",
    "        i_ru, i_dc = pick_row_index(df.index)\n",
    "        if i_ru is None and i_dc is None:\n",
    "            raise ValueError(f\"[{sheet}] RU/DC rows not found; please adjust KW_RU/KW_DC. Index={df.index.tolist()}\")\n",
    "\n",
    "        # Select RU row\n",
    "        ru_row = None\n",
    "        for kw in KW_RU:\n",
    "            cand = df.index[df.index.str.contains(kw, case=False, na=False)]\n",
    "            if len(cand) > 0:\n",
    "                ru_row = df.loc[cand[0]]\n",
    "                break\n",
    "        # Select DC row\n",
    "        dc_row = None\n",
    "        for kw in KW_DC:\n",
    "            cand = df.index[df.index.str.contains(kw, case=False, na=False)]\n",
    "            if len(cand) > 0:\n",
    "                dc_row = df.loc[cand[0]]\n",
    "                break\n",
    "\n",
    "        # Keep only year-like columns\n",
    "        year_cols = []\n",
    "        for c in df.columns:\n",
    "            try:\n",
    "                y = int(str(c))\n",
    "                if 1900 <= y <= 2100:\n",
    "                    year_cols.append(c)\n",
    "            except:\n",
    "                pass\n",
    "        if not year_cols:\n",
    "            raise ValueError(f\"[{sheet}] No year columns found; columns={df.columns.tolist()}\")\n",
    "\n",
    "        ru_s = pd.to_numeric(ru_row[year_cols], errors=\"coerce\") if ru_row is not None else pd.Series(index=year_cols, dtype=float)\n",
    "        dc_s = pd.to_numeric(dc_row[year_cols], errors=\"coerce\") if dc_row is not None else pd.Series(index=year_cols, dtype=float)\n",
    "\n",
    "        tmp = pd.DataFrame({\n",
    "            \"Region\": sheet,\n",
    "            \"Year\": [int(y) for y in year_cols],\n",
    "            \"RU_share\": ru_s.values,\n",
    "            \"DC_share\": dc_s.values\n",
    "        })\n",
    "        long_rows.append(tmp)\n",
    "\n",
    "    long_df = pd.concat(long_rows, ignore_index=True)\n",
    "    long_df[[\"RU_share\", \"DC_share\"]] = long_df[[\"RU_share\", \"DC_share\"]].fillna(0.0)\n",
    "    return long_df  # cols: Region, Year, RU_share, DC_share\n",
    "\n",
    "def forward_mean(series: pd.Series, window: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Forward rolling mean (y..y+H-1), keeping signs unchanged; clipping/merging done later.\n",
    "    Method: Reverse time series -> backward rolling -> reverse back.\n",
    "    \"\"\"\n",
    "    s = series.sort_index(ascending=True)\n",
    "    fm = s.iloc[::-1].rolling(window=window, min_periods=1).mean().iloc[::-1]\n",
    "    return fm.reindex(s.index)\n",
    "\n",
    "# ==================== Main Process ====================\n",
    "\n",
    "# Table 1: Total Investment\n",
    "inv_df = read_table1(PATH_INVEST)  # Year, TotalCost\n",
    "\n",
    "# Table 2: Raw Growth (No clipping, no merging)\n",
    "growth_raw = read_table2_all_regions_raw(PATH_GROWTH)  # Region, Year, RES_raw, DC_raw\n",
    "\n",
    "# Align Year Range: Intersection with investment years (averaging done within this set per region)\n",
    "years = sorted(set(inv_df[\"Year\"].astype(int)))\n",
    "years = sorted(set(years).intersection(set(growth_raw[\"Year\"].astype(int))))\n",
    "inv_df = inv_df[inv_df[\"Year\"].isin(years)].copy()\n",
    "\n",
    "regions = sorted(growth_raw[\"Region\"].unique())\n",
    "\n",
    "# === Calculate \"Forward Mean\" ===\n",
    "# Pivot to wide format for rolling: index=Year, columns=Region\n",
    "res_wide_raw = growth_raw.pivot(index=\"Year\", columns=\"Region\", values=\"RES_raw\").reindex(years).sort_index()\n",
    "dc_wide_raw  = growth_raw.pivot(index=\"Year\", columns=\"Region\", values=\"DC_raw\").reindex(years).sort_index()\n",
    "res_wide_raw = res_wide_raw.fillna(0.0)\n",
    "dc_wide_raw  = dc_wide_raw.fillna(0.0)\n",
    "\n",
    "# Calculate forward mean for each region\n",
    "res_fw_raw = pd.DataFrame(index=years, columns=regions, dtype=float)\n",
    "dc_fw_raw  = pd.DataFrame(index=years, columns=regions, dtype=float)\n",
    "for r in regions:\n",
    "    res_fw_raw[r] = forward_mean(res_wide_raw[r], LOOKAHEAD_YEARS)\n",
    "    dc_fw_raw[r]  = forward_mean(dc_wide_raw[r],  LOOKAHEAD_YEARS)\n",
    "\n",
    "# === Apply AFTER averaging: Set RES<0 to 0, add absolute value to DC ===\n",
    "res_fw_pos = res_fw_raw.clip(lower=0.0)\n",
    "dc_fw_adj  = dc_fw_raw + res_fw_raw.clip(upper=0.0).abs()\n",
    "\n",
    "# Optional: Drop rows where RES/DC are both 0 after averaging (instead of before)\n",
    "# Not dropping rows directly here, handled naturally during aggregation; uncomment to enforce dropping:\n",
    "# if DROP_ROWS_IF_ALL_ZERO:\n",
    "#     mask_nonzero = ~((res_fw_pos == 0.0) & (dc_fw_adj == 0.0))\n",
    "#     res_fw_pos = res_fw_pos.where(mask_nonzero, other=0.0)\n",
    "#     dc_fw_adj  = dc_fw_adj.where(mask_nonzero,  other=0.0)\n",
    "\n",
    "# Melt averaged wide table back to long format for calculation\n",
    "growth_fw = (\n",
    "    res_fw_pos.stack().rename(\"RES_pos\").to_frame()\n",
    "    .join(dc_fw_adj.stack().rename(\"DC\"))\n",
    "    .reset_index().rename(columns={\"level_0\":\"Year\",\"level_1\":\"Region\"})\n",
    ")\n",
    "growth_fw = growth_fw[[\"Region\",\"Year\",\"RES_pos\",\"DC\"]].sort_values([\"Year\",\"Region\"])\n",
    "\n",
    "# Read Table 3: RU/DC allocation splits\n",
    "splits = read_table3_splits(PATH_SPLIT)  # Region, Year, RU_share, DC_share\n",
    "\n",
    "# 1) Allocate annual investment to regions based on \"(RES_pos+DC) share\" (after averaging)\n",
    "growth_fw[\"TotalGrow\"] = growth_fw[\"RES_pos\"] + growth_fw[\"DC\"]\n",
    "\n",
    "year_den = growth_fw.groupby(\"Year\", as_index=False)[\"TotalGrow\"].sum().rename(columns={\"TotalGrow\":\"YearGrowSum\"})\n",
    "g2 = growth_fw.merge(year_den, on=\"Year\", how=\"left\")\n",
    "g2[\"YearGrowSum\"] = g2[\"YearGrowSum\"].replace(0, pd.NA)\n",
    "\n",
    "g2 = g2.merge(inv_df, on=\"Year\", how=\"left\")\n",
    "\n",
    "# Regional Total Cost\n",
    "g2[\"RegionCost\"] = (g2[\"TotalGrow\"] / g2[\"YearGrowSum\"]) * g2[\"TotalCost\"]\n",
    "g2[\"RegionCost\"] = g2[\"RegionCost\"].fillna(0.0)\n",
    "\n",
    "# 2) Intra-region split (using averaged shares)\n",
    "g2[\"inner_den\"] = g2[\"RES_pos\"] + g2[\"DC\"]\n",
    "g2.loc[g2[\"inner_den\"] == 0, \"inner_den\"] = pd.NA\n",
    "\n",
    "g2[\"RegionCost_DCgrowth\"]  = (g2[\"DC\"]      / g2[\"inner_den\"]) * g2[\"RegionCost\"]\n",
    "g2[\"RegionCost_RESgrowth\"] = (g2[\"RES_pos\"] / g2[\"inner_den\"]) * g2[\"RegionCost\"]\n",
    "g2[[\"RegionCost_DCgrowth\",\"RegionCost_RESgrowth\"]] = g2[[\"RegionCost_DCgrowth\",\"RegionCost_RESgrowth\"]].fillna(0.0)\n",
    "\n",
    "# 3) Level 1 Summary (CAISO-wide)\n",
    "level1 = g2.groupby(\"Year\", as_index=False).agg(\n",
    "    DC_growth_cost    = (\"RegionCost_DCgrowth\",\"sum\"),\n",
    "    NonDC_growth_cost = (\"RegionCost_RESgrowth\",\"sum\"),\n",
    "    Total             = (\"RegionCost\",\"sum\")\n",
    ")\n",
    "level1.to_csv(OUTDIR/f\"caiso_level1_totals_fw{LOOKAHEAD_YEARS}y.csv\", index=False)\n",
    "\n",
    "# 4) Level 2 Summary (By Region)\n",
    "level2 = g2[[\"Year\",\"Region\",\"RegionCost\",\"RegionCost_DCgrowth\",\"RegionCost_RESgrowth\"]].copy()\n",
    "level2 = level2.sort_values([\"Year\",\"Region\"])\n",
    "level2.to_csv(OUTDIR/f\"caiso_level2_by_region_fw{LOOKAHEAD_YEARS}y.csv\", index=False)\n",
    "\n",
    "# 5) Level 3 Summary (Calculate final RU vs DC burden per region based on splits)\n",
    "g3 = g2.merge(splits, on=[\"Region\",\"Year\"], how=\"left\")\n",
    "g3[[\"RU_share\",\"DC_share\"]] = g3[[\"RU_share\",\"DC_share\"]].fillna(0.0)\n",
    "\n",
    "# For Sankey conservation, apply RU/DC ratios separately to \"DC Growth Cost\" / \"Non-DC Growth Cost\"\n",
    "g3[\"RU_charge_from_DCgrowth\"]   = g3[\"RegionCost_DCgrowth\"]  * g3[\"RU_share\"]\n",
    "g3[\"DC_charge_from_DCgrowth\"]   = g3[\"RegionCost_DCgrowth\"]  * g3[\"DC_share\"]\n",
    "g3[\"RU_charge_from_RESgrowth\"]  = g3[\"RegionCost_RESgrowth\"] * g3[\"RU_share\"]\n",
    "g3[\"DC_charge_from_RESgrowth\"]  = g3[\"RegionCost_RESgrowth\"] * g3[\"DC_share\"]\n",
    "\n",
    "# Also provide allocation based on total regional cost (for reconciliation)\n",
    "g3[\"RU_charge_total\"] = g3[\"RegionCost\"] * g3[\"RU_share\"]\n",
    "g3[\"DC_charge_total\"] = g3[\"RegionCost\"] * g3[\"DC_share\"]\n",
    "\n",
    "level3 = g3[[\n",
    "    \"Year\",\"Region\",\"RU_share\",\"DC_share\",\n",
    "    \"RU_charge_total\",\"DC_charge_total\",\n",
    "    \"RU_charge_from_DCgrowth\",\"DC_charge_from_DCgrowth\",\n",
    "    \"RU_charge_from_RESgrowth\",\"DC_charge_from_RESgrowth\"\n",
    "]].sort_values([\"Year\",\"Region\"])\n",
    "level3.to_csv(OUTDIR/f\"caiso_level3_user_burden_fw{LOOKAHEAD_YEARS}y.csv\", index=False)\n",
    "\n",
    "# 6) Sankey Links (by Year), 3-layer structure:\n",
    "#    L0:  [CAISO-DC, CAISO-NonDC]\n",
    "#    L1:  [Region DC growth, Region NonDC growth]\n",
    "#    L2:  [Region RU, Region DC]\n",
    "sankey_links = []\n",
    "for y, sub in g3.groupby(\"Year\"):\n",
    "    for _, r in sub.iterrows():\n",
    "        sankey_links.append({\n",
    "            \"Year\": y, \"source\": \"CAISO-DC growth\",\n",
    "            \"target\": f\"{r['Region']} - DC growth\",\n",
    "            \"value\": float(r[\"RegionCost_DCgrowth\"])\n",
    "        })\n",
    "        sankey_links.append({\n",
    "            \"Year\": y, \"source\": \"CAISO-NonDC growth\",\n",
    "            \"target\": f\"{r['Region']} - NonDC growth\",\n",
    "            \"value\": float(r[\"RegionCost_RESgrowth\"])\n",
    "        })\n",
    "        sankey_links.append({\n",
    "            \"Year\": y, \"source\": f\"{r['Region']} - DC growth\",\n",
    "            \"target\": f\"{r['Region']} - RU\",\n",
    "            \"value\": float(r[\"RU_charge_from_DCgrowth\"])\n",
    "        })\n",
    "        sankey_links.append({\n",
    "            \"Year\": y, \"source\": f\"{r['Region']} - DC growth\",\n",
    "            \"target\": f\"{r['Region']} - DC\",\n",
    "            \"value\": float(r[\"DC_charge_from_DCgrowth\"])\n",
    "        })\n",
    "        sankey_links.append({\n",
    "            \"Year\": y, \"source\": f\"{r['Region']} - NonDC growth\",\n",
    "            \"target\": f\"{r['Region']} - RU\",\n",
    "            \"value\": float(r[\"RU_charge_from_RESgrowth\"])\n",
    "        })\n",
    "        sankey_links.append({\n",
    "            \"Year\": y, \"source\": f\"{r['Region']} - NonDC growth\",\n",
    "            \"target\": f\"{r['Region']} - DC\",\n",
    "            \"value\": float(r[\"DC_charge_from_RESgrowth\"])\n",
    "        })\n",
    "\n",
    "pd.DataFrame(sankey_links).to_csv(OUTDIR/f\"caiso_sankey_links_fw{LOOKAHEAD_YEARS}y.csv\", index=False)\n",
    "\n",
    "# Extra Output: Wide tables \"before/after averaging\" for verification\n",
    "with pd.ExcelWriter(OUTDIR / f\"caiso_forward_mean_debug_fw{LOOKAHEAD_YEARS}y.xlsx\") as w:\n",
    "    res_wide_raw.to_excel(w, sheet_name=\"RES_raw_wide\")\n",
    "    dc_wide_raw.to_excel(w,  sheet_name=\"DC_raw_wide\")\n",
    "    res_fw_raw.to_excel(w,   sheet_name=\"RES_fw_raw\")\n",
    "    dc_fw_raw.to_excel(w,    sheet_name=\"DC_fw_raw\")\n",
    "    res_fw_pos.to_excel(w,   sheet_name=\"RES_fw_after_clip\")\n",
    "    dc_fw_adj.to_excel(w,    sheet_name=\"DC_fw_after_merge\")\n",
    "print(\"✅ Done! Output generated:\")\n",
    "print(\"-\", OUTDIR / f\"caiso_level1_totals_fw{LOOKAHEAD_YEARS}y.csv\")\n",
    "print(\"-\", OUTDIR / f\"caiso_level2_by_region_fw{LOOKAHEAD_YEARS}y.csv\")\n",
    "print(\"-\", OUTDIR / f\"caiso_level3_user_burden_fw{LOOKAHEAD_YEARS}y.csv\")\n",
    "print(\"-\", OUTDIR / f\"caiso_sankey_links_fw{LOOKAHEAD_YEARS}y.csv\")\n",
    "print(\"-\", OUTDIR / f\"caiso_forward_mean_debug_fw{LOOKAHEAD_YEARS}y.xlsx\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成！已输出：\n",
      "- rider/CAISO/caiso_level1_totals_fw5y.csv\n",
      "- rider/CAISO/caiso_level2_by_region_fw5y.csv\n",
      "- rider/CAISO/caiso_level3_user_burden_fw5y.csv\n",
      "- rider/CAISO/caiso_sankey_links_fw5y.csv\n",
      "- rider/CAISO/caiso_forward_mean_debug_fw5y.xlsx\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybkb",
   "language": "python",
   "name": "pybkb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
