{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ========================= Configuration =========================\n",
    "# Table 1: Project Investment (Long format): year / region / cost\n",
    "PATH_INVEST = Path( \"./load and costs/MISO/MISO_cost.xlsx\" )\n",
    "COL_YEAR_1   = \"year\"\n",
    "COL_REGION_1 = \"region\"\n",
    "COL_COST_1   = \"cost\"\n",
    "\n",
    "# Table 2: Regional Sub-tables; Columns must include Year / Residential Growth / DC Growth\n",
    "PATH_GROWTH = Path( \"./load and costs/MISO/22_load_compare.xlsx\" )\n",
    "# Table 3: Regional Sub-tables; Columns must include Year / RU Share / DC Share\n",
    "PATH_SHARE  = Path( \"./rider/MISO/00_MISO_share.xlsx\" )\n",
    "\n",
    "# Output Directory\n",
    "OUTDIR = Path( \"./rider/MISO\" )\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Lookahead Window\n",
    "LOOKAHEAD = 5  # 5-Year Forward Rolling Sum\n",
    "\n",
    "# Column Alias Mapping (Normalized -> Standard)\n",
    "# Adjust these based on your actual Excel headers\n",
    "KEY_MAP = {\n",
    "    \"year\": \"year\",\n",
    "    \"年份\": \"year\",\n",
    "    \"region\": \"region\",\n",
    "    \"zone\": \"region\",\n",
    "    \"area\": \"region\",\n",
    "    \"cost\": \"cost\",\n",
    "    \"totalcost\": \"cost\",\n",
    "    \"investment\": \"cost\",\n",
    "    \"resdelta\": \"res_delta\",\n",
    "    \"residentialdelta\": \"res_delta\",\n",
    "    \"res\": \"res_delta\",\n",
    "    \"dcdelta\": \"dc_delta\",\n",
    "    \"dc_delta\": \"dc_delta\",\n",
    "    \"dc\": \"dc_delta\",\n",
    "    \"ru\": \"ru_share\",\n",
    "    \"residential\": \"ru_share\",\n",
    "    \"ru_share\": \"ru_share\",\n",
    "    \"dc_share\": \"dc_share\"\n",
    "}\n",
    "\n",
    "def _norm(s):\n",
    "    \"\"\"Normalize string: remove non-alphanumeric characters, convert to lowercase.\"\"\"\n",
    "    if pd.isna(s): return \"\"\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", str(s).lower())\n",
    "\n",
    "def rename_cols(df):\n",
    "    \"\"\"Clean column names based on KEY_MAP.\"\"\"\n",
    "    new_cols = {}\n",
    "    for c in df.columns:\n",
    "        nc = _norm(c)\n",
    "        if nc in KEY_MAP:\n",
    "            new_cols[c] = KEY_MAP[nc]\n",
    "    return df.rename(columns=new_cols)\n",
    "\n",
    "# ========================= 1. Load Data =========================\n",
    "\n",
    "# --- 1.1 Read Investment Table (Table 1) ---\n",
    "df_inv = pd.read_excel(PATH_INVEST)\n",
    "df_inv = rename_cols(df_inv)\n",
    "# Ensure required columns exist\n",
    "for c in [\"year\", \"region\", \"cost\"]:\n",
    "    if c not in df_inv.columns:\n",
    "        raise ValueError(f\"Table 1 is missing column: {c}\")\n",
    "# Aggregation: One record per Region-Year\n",
    "inv_agg = df_inv.groupby([\"year\", \"region\"], as_index=False)[\"cost\"].sum()\n",
    "\n",
    "# --- 1.2 Read Growth Table (Table 2) ---\n",
    "# Read all sheets, assume each sheet is a Region\n",
    "# Keep raw values (positive/negative), do not zero-floor yet\n",
    "sheets_growth = pd.read_excel(PATH_GROWTH, sheet_name=None)\n",
    "growth_list = []\n",
    "for sheet_name, df in sheets_growth.items():\n",
    "    df = rename_cols(df)\n",
    "    if \"year\" not in df.columns:\n",
    "        # Try to identify the first column as Year\n",
    "        df = df.rename(columns={df.columns[0]: \"year\"})\n",
    "\n",
    "    # Ensure Res/DC columns exist\n",
    "    if \"res_delta\" not in df.columns or \"dc_delta\" not in df.columns:\n",
    "        # Fallback: Identify by column index (1=Res, 3=DC) or keyword search?\n",
    "        # Simple logic: If columns 1 and 3 are numeric, assume they are Res and DC\n",
    "        # (Adjust logic based on actual file structure)\n",
    "        cols = df.columns\n",
    "        if len(cols) >= 4:\n",
    "            # Assuming Col 1 is Res, Col 3 is DC (0-based indices 1 and 3)\n",
    "            # This is risky, better to rely on keywords.\n",
    "            pass\n",
    "\n",
    "    df[\"region\"] = sheet_name # Use sheet name as region\n",
    "    growth_list.append(df[[\"year\", \"region\", \"res_delta\", \"dc_delta\"]])\n",
    "\n",
    "df_growth_raw = pd.concat(growth_list, ignore_index=True)\n",
    "df_growth_raw[\"year\"] = pd.to_numeric(df_growth_raw[\"year\"], errors=\"coerce\")\n",
    "df_growth_raw = df_growth_raw.dropna(subset=[\"year\"])\n",
    "df_growth_raw[\"year\"] = df_growth_raw[\"year\"].astype(int)\n",
    "\n",
    "# --- 1.3 Read Share Table (Table 3) ---\n",
    "# Format: Each sheet is a Region. Rows are \"RU\", \"DC\". Columns are Years.\n",
    "sheets_share = pd.read_excel(PATH_SHARE, sheet_name=None, index_col=0)\n",
    "share_list = []\n",
    "for sheet_name, df in sheets_share.items():\n",
    "    # Transpose: Rows become Years, Columns become RU/DC\n",
    "    df_t = df.T\n",
    "    df_t.index.name = \"year\"\n",
    "    df_t = df_t.reset_index()\n",
    "    # Clean column names (Year, RU, DC)\n",
    "    df_t = rename_cols(df_t)\n",
    "\n",
    "    # Identify RU and DC columns in the transposed dataframe\n",
    "    # The original index (now columns) might be \"RU\", \"DC\", \"Residential\" etc.\n",
    "    # We need to map them to 'ru_share', 'dc_share'\n",
    "    mapped_cols = {}\n",
    "    for c in df_t.columns:\n",
    "        nc = _norm(c)\n",
    "        if \"ru\" in nc or \"res\" in nc:\n",
    "            mapped_cols[c] = \"ru_share\"\n",
    "        elif \"dc\" in nc:\n",
    "            mapped_cols[c] = \"dc_share\"\n",
    "        elif \"year\" in nc or str(c).isdigit(): # If year column wasn't handled\n",
    "            mapped_cols[c] = \"year\"\n",
    "\n",
    "    df_t = df_t.rename(columns=mapped_cols)\n",
    "    df_t[\"region\"] = sheet_name\n",
    "\n",
    "    if \"ru_share\" in df_t.columns and \"dc_share\" in df_t.columns:\n",
    "        share_list.append(df_t[[\"year\", \"region\", \"ru_share\", \"dc_share\"]])\n",
    "\n",
    "df_share = pd.concat(share_list, ignore_index=True)\n",
    "df_share[\"year\"] = pd.to_numeric(df_share[\"year\"], errors=\"coerce\")\n",
    "df_share = df_share.dropna(subset=[\"year\"])\n",
    "df_share[\"year\"] = df_share[\"year\"].astype(int)\n",
    "\n",
    "# ========================= 2. Calculation Logic =========================\n",
    "\n",
    "# 2.1 Calculate Forward Rolling Sum\n",
    "# Logic: For Year T, sum(LoadDelta[T : T+LOOKAHEAD])\n",
    "# Implementation: Sort descending -> Rolling Sum -> Shift back?\n",
    "# Or: Sort ascending -> Inverse rolling?\n",
    "# Easier: Rolling on inverted index.\n",
    "\n",
    "def calc_forward_rolling(df, val_col, window):\n",
    "    # Sort by Year Ascending\n",
    "    df = df.sort_values(\"year\")\n",
    "    # Invert, calculate rolling sum (looking \"backward\" which is forward in time), then invert back\n",
    "    # min_periods=1 ensures we get values even at the end of the series\n",
    "    rolling = df[val_col][::-1].rolling(window=window, min_periods=1).sum()[::-1]\n",
    "    return rolling\n",
    "\n",
    "# Calculate per region\n",
    "df_growth_raw = df_growth_raw.sort_values([\"region\", \"year\"])\n",
    "df_growth_raw[\"res_roll\"] = df_growth_raw.groupby(\"region\")\\\n",
    "                                         .apply(lambda x: calc_forward_rolling(x, \"res_delta\", LOOKAHEAD))\\\n",
    "                                         .reset_index(level=0, drop=True)\n",
    "df_growth_raw[\"dc_roll\"]  = df_growth_raw.groupby(\"region\")\\\n",
    "                                         .apply(lambda x: calc_forward_rolling(x, \"dc_delta\",  LOOKAHEAD))\\\n",
    "                                         .reset_index(level=0, drop=True)\n",
    "\n",
    "# 2.2 Load Increment Attribution Calculation\n",
    "# Rule:\n",
    "# 1. Zero-floor: If Rolling Sum < 0, treat as 0.\n",
    "# 2. Calculate proportions:\n",
    "#    - Denom = max(0, Res_Roll) + max(0, DC_Roll)\n",
    "#    - If Denom == 0, then Rate = 0 (avoid div/0)\n",
    "#    - Res_Rate = max(0, Res_Roll) / Denom\n",
    "#    - DC_Rate  = max(0, DC_Roll)  / Denom\n",
    "\n",
    "df_calc = df_growth_raw.copy()\n",
    "df_calc[\"res_pos\"] = df_calc[\"res_roll\"].clip(lower=0)\n",
    "df_calc[\"dc_pos\"]  = df_calc[\"dc_roll\"].clip(lower=0)\n",
    "df_calc[\"denom\"]   = df_calc[\"res_pos\"] + df_calc[\"dc_pos\"]\n",
    "\n",
    "# Calculate internal allocation ratio (within the incremental part)\n",
    "df_calc[\"ratio_res\"] = np.where(df_calc[\"denom\"] > 0, df_calc[\"res_pos\"] / df_calc[\"denom\"], 0.0)\n",
    "df_calc[\"ratio_dc\"]  = np.where(df_calc[\"denom\"] > 0, df_calc[\"dc_pos\"]  / df_calc[\"denom\"], 0.0)\n",
    "\n",
    "# 2.3 Merge Investment and Share Data\n",
    "# Merge structure: Investment (Main) <- Growth Ratio <- RU/DC Share\n",
    "# Note: Ensure Regions match.\n",
    "\n",
    "# Standardize region names (uppercase, strip)\n",
    "inv_agg[\"region\"] = inv_agg[\"region\"].astype(str).str.strip().str.upper()\n",
    "df_calc[\"region\"] = df_calc[\"region\"].astype(str).str.strip().str.upper()\n",
    "df_share[\"region\"] = df_share[\"region\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Merge Investment + Growth\n",
    "merged = pd.merge(inv_agg, df_calc, on=[\"year\", \"region\"], how=\"left\")\n",
    "# Fill missing growth data with 0 (implies no growth -> no specific attribution?)\n",
    "# Or maybe fill ratios? If no growth data, we can't attribute by growth.\n",
    "merged[[\"ratio_res\", \"ratio_dc\"]] = merged[[\"ratio_res\", \"ratio_dc\"]].fillna(0.0)\n",
    "\n",
    "# Calculate Cost Attribution\n",
    "merged[\"cost_to_res_growth\"] = merged[\"cost\"] * merged[\"ratio_res\"]\n",
    "merged[\"cost_to_dc_growth\"]  = merged[\"cost\"] * merged[\"ratio_dc\"]\n",
    "# Note: If denom=0, Cost remains unallocated by growth logic.\n",
    "# You might want a fallback or just track it as \"Unassigned\".\n",
    "merged[\"cost_unassigned\"] = merged[\"cost\"] - (merged[\"cost_to_res_growth\"] + merged[\"cost_to_dc_growth\"])\n",
    "\n",
    "# Merge RU/DC Share (for final user burden)\n",
    "# This share splits the \"Growth Cost\" further? Or splits the Total Cost?\n",
    "# Usually, Sankey logic:\n",
    "# Layer 1: Total Cost -> [Res Growth Portion] / [DC Growth Portion]\n",
    "# Layer 2: [Res Growth Portion] -> RU (100%?) or RU/DC split?\n",
    "#          [DC Growth Portion] -> DC (100%?)\n",
    "# Based on previous scripts (PJM/CAISO), usually:\n",
    "# - \"Cost caused by DC Growth\" is allocated to DC users?\n",
    "# - Or allocated to Zone, then split by User Share?\n",
    "# Let's check CAISO logic:\n",
    "#   RU_charge_from_DCgrowth = RegionCost_DCgrowth * RU_share\n",
    "#   DC_charge_from_DCgrowth = RegionCost_DCgrowth * DC_share\n",
    "#   (Meaning even if DC caused the growth, the cost enters the pool and is shared by RU/DC based on load share)\n",
    "# Let's apply this logic (Sankey Conservation).\n",
    "\n",
    "merged = pd.merge(merged, df_share, on=[\"year\", \"region\"], how=\"left\")\n",
    "# Fill missing shares (maybe defaults?)\n",
    "merged[[\"ru_share\", \"dc_share\"]] = merged[[\"ru_share\", \"dc_share\"]].fillna(0.0)\n",
    "\n",
    "# Final calculation\n",
    "# 1. From Res Growth Cost -> Split to RU / DC\n",
    "merged[\"paid_by_ru_from_res\"] = merged[\"cost_to_res_growth\"] * merged[\"ru_share\"]\n",
    "merged[\"paid_by_dc_from_res\"] = merged[\"cost_to_res_growth\"] * merged[\"dc_share\"]\n",
    "\n",
    "# 2. From DC Growth Cost -> Split to RU / DC\n",
    "merged[\"paid_by_ru_from_dc\"] = merged[\"cost_to_dc_growth\"] * merged[\"ru_share\"]\n",
    "merged[\"paid_by_dc_from_dc\"] = merged[\"cost_to_dc_growth\"] * merged[\"dc_share\"]\n",
    "\n",
    "# 3. Unassigned (if any) -> Split? Or keep separate?\n",
    "# Let's assume unassigned (no growth) follows general share\n",
    "merged[\"paid_by_ru_from_unassigned\"] = merged[\"cost_unassigned\"] * merged[\"ru_share\"]\n",
    "merged[\"paid_by_dc_from_unassigned\"] = merged[\"cost_unassigned\"] * merged[\"dc_share\"]\n",
    "\n",
    "# Total Paid\n",
    "merged[\"paid_total_ru\"] = merged[\"paid_by_ru_from_res\"] + merged[\"paid_by_ru_from_dc\"] + merged[\"paid_by_ru_from_unassigned\"]\n",
    "merged[\"paid_total_dc\"] = merged[\"paid_by_dc_from_res\"] + merged[\"paid_by_dc_from_dc\"] + merged[\"paid_by_dc_from_unassigned\"]\n",
    "\n",
    "# ========================= 3. Generate Output =========================\n",
    "\n",
    "# 3.1 Intermediate Table (Level 2: By Region)\n",
    "# Cols: Year, Region, TotalCost, Cost_ResGrowth, Cost_DCGrowth, Cost_Unassigned\n",
    "lev2 = merged[[\"year\", \"region\", \"cost\", \"cost_to_res_growth\", \"cost_to_dc_growth\", \"cost_unassigned\"]].copy()\n",
    "lev2.to_csv(OUTDIR/\"miso_level2_alloc_by_growth.csv\", index=False)\n",
    "\n",
    "# 3.2 User Burden (Level 3)\n",
    "lev3 = merged[[\"year\", \"region\", \"paid_total_ru\", \"paid_total_dc\"]].copy()\n",
    "lev3.to_csv(OUTDIR/\"miso_level3_user_burden.csv\", index=False)\n",
    "\n",
    "# 3.3 Sankey Links\n",
    "# Format: Source, Target, Value, Year\n",
    "# Layers:\n",
    "# L1: MISO_Invest -> Region_Total (Skip this? Usually Source -> GrowthType)\n",
    "# Let's match CAISO/PJM style:\n",
    "# Source: \"MISO Grid\" -> Target: \"Region - ResGrowth\" / \"Region - DCGrowth\"\n",
    "# Then: \"Region - ResGrowth\" -> RU / DC\n",
    "links = []\n",
    "\n",
    "for _, row in merged.iterrows():\n",
    "    y = row[\"year\"]\n",
    "    r = row[\"region\"]\n",
    "\n",
    "    # L1: Grid -> Growth Drivers\n",
    "    # Node names\n",
    "    node_grid = \"MISO Grid\"\n",
    "    node_res_g = f\"{r} ResGrowth\"\n",
    "    node_dc_g  = f\"{r} DCGrowth\"\n",
    "    node_none  = f\"{r} Unassigned\"\n",
    "\n",
    "    if row[\"cost_to_res_growth\"] > 0:\n",
    "        links.append({\"year\": y, \"source\": node_grid, \"target\": node_res_g, \"value\": row[\"cost_to_res_growth\"]})\n",
    "    if row[\"cost_to_dc_growth\"] > 0:\n",
    "        links.append({\"year\": y, \"source\": node_grid, \"target\": node_dc_g,  \"value\": row[\"cost_to_dc_growth\"]})\n",
    "    if row[\"cost_unassigned\"] > 0:\n",
    "        links.append({\"year\": y, \"source\": node_grid, \"target\": node_none,  \"value\": row[\"cost_unassigned\"]})\n",
    "\n",
    "    # L2: Growth Drivers -> Users (RU/DC)\n",
    "    node_ru = f\"{r} RU\"\n",
    "    node_dc = f\"{r} DC\"\n",
    "\n",
    "    # From Res Growth\n",
    "    if row[\"paid_by_ru_from_res\"] > 0:\n",
    "        links.append({\"year\": y, \"source\": node_res_g, \"target\": node_ru, \"value\": row[\"paid_by_ru_from_res\"]})\n",
    "    if row[\"paid_by_dc_from_res\"] > 0:\n",
    "        links.append({\"year\": y, \"source\": node_res_g, \"target\": node_dc, \"value\": row[\"paid_by_dc_from_res\"]})\n",
    "\n",
    "    # From DC Growth\n",
    "    if row[\"paid_by_ru_from_dc\"] > 0:\n",
    "        links.append({\"year\": y, \"source\": node_dc_g, \"target\": node_ru, \"value\": row[\"paid_by_ru_from_dc\"]})\n",
    "    if row[\"paid_by_dc_from_dc\"] > 0:\n",
    "        links.append({\"year\": y, \"source\": node_dc_g, \"target\": node_dc, \"value\": row[\"paid_by_dc_from_dc\"]})\n",
    "\n",
    "    # From Unassigned\n",
    "    if row[\"paid_by_ru_from_unassigned\"] > 0:\n",
    "        links.append({\"year\": y, \"source\": node_none, \"target\": node_ru, \"value\": row[\"paid_by_ru_from_unassigned\"]})\n",
    "    if row[\"paid_by_dc_from_unassigned\"] > 0:\n",
    "        links.append({\"year\": y, \"source\": node_none, \"target\": node_dc, \"value\": row[\"paid_by_dc_from_unassigned\"]})\n",
    "\n",
    "df_links = pd.DataFrame(links)\n",
    "df_links.to_csv(OUTDIR/\"miso_sankey_links.csv\", index=False)\n",
    "\n",
    "# ----------------- Check -----------------\n",
    "# Verify totals\n",
    "total_inv = inv_agg[\"cost\"].sum()\n",
    "total_allocated = df_links[df_links[\"source\"]==\"MISO Grid\"][\"value\"].sum()\n",
    "print(f\"Total Investment: {total_inv:,.2f}\")\n",
    "print(f\"Total Allocated (L1): {total_allocated:,.2f}\")\n",
    "print(f\"Diff: {total_inv - total_allocated:,.2f}\")\n",
    "\n",
    "# Also check Level 2 + 3 combined output for Tableau\n",
    "# Region | Year | Type (ResGrowth/DCGrowth/Unassigned) | Paid_RU | Paid_DC\n",
    "# Melt and Merge\n",
    "# (Simplified: Just use the Level 3 CSV or Links for visualization)\n",
    "\n",
    "# Final National Burden (Raw Scale)\n",
    "final_nat_raw = lev3.groupby(\"year\", as_index=False)[[\"paid_total_ru\", \"paid_total_dc\"]].sum()\n",
    "final_nat_raw.to_csv(OUTDIR/\"check_final_paid_national_raw.csv\", index=False)\n",
    "\n",
    "print(\"✅ All done. Output directory:\", OUTDIR.resolve())\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybkb",
   "language": "python",
   "name": "pybkb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
