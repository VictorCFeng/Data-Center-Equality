{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ============ Configuration ============\n",
    "PATH_PROJECTS  = Path(\"./load and costs/PJM/projects_with_dc_flags.xlsx\")  # Output from previous step (contains DC_ATTR_*, teac_cost, allocation columns)\n",
    "SHEET_PROJECTS = 0  # Or specify the sheet name\n",
    "PATH_RUDC_WB  = Path(\"./rider/PJM/00_PJM_share.xlsx\")     # One region per sheet, contains RU/DC rows, columns are years\n",
    "OUT_PATH      = Path(\"./rider/PJM/sankey_inputs.xlsx\")\n",
    "# ====================================================\n",
    "\n",
    "# Fixed Excel column range C..AB as \"Zone Allocation\" columns (Do not auto-detect)\n",
    "# C -> 3rd column; AB -> 28th column; pandas 0-based index is 2..27 (slice is right-exclusive)\n",
    "ZONE_COL_SLICE = slice(2, 28)  # [2, 28)\n",
    "\n",
    "def _norm(s):\n",
    "    return str(s).strip().upper().replace(\"\\n\",\" \").replace(\"\\t\",\" \")\n",
    "\n",
    "def find_col(df, candidates):\n",
    "    \"\"\"Loose matching for common column names (Only for year/owner/teac_cost; allocation columns fixed to C..AB)\"\"\"\n",
    "    keymap = { ''.join(c.lower().split()).replace('_',''): c for c in df.columns }\n",
    "    for cand in candidates:\n",
    "        k = ''.join(cand.lower().split()).replace('_','')\n",
    "        if k in keymap:\n",
    "            return keymap[k]\n",
    "    raise KeyError(f\"Column name not found; candidates={candidates}; available columns={list(df.columns)}\")\n",
    "\n",
    "def sum_alloc_by_zone_year(df_alloc, years, zone_cols, zone_map, value_name):\n",
    "    \"\"\"Prevent many-to-many explosion: Aggregate by year in wide format first, then melt to long format\"\"\"\n",
    "    tmp = df_alloc.copy()\n",
    "    tmp[\"year\"] = years.values\n",
    "    wide = tmp.groupby(\"year\", as_index=False)[zone_cols].sum()\n",
    "    long = wide.melt(id_vars=[\"year\"], var_name=\"zone_col\", value_name=value_name)\n",
    "    long[\"zone\"] = long[\"zone_col\"].map(zone_map)\n",
    "    long = long.groupby([\"zone\",\"year\"], as_index=False)[value_name].sum()\n",
    "    return long\n",
    "\n",
    "# ---------- 0) Read RU/DC Allocation Shares ----------\n",
    "rudc = pd.read_excel(PATH_RUDC_WB, sheet_name=None, header=0, index_col=0)\n",
    "rows = []\n",
    "for zname, df in rudc.items():\n",
    "    if df is None or df.empty:\n",
    "        continue\n",
    "    idx = { _norm(i): i for i in df.index.astype(str) }\n",
    "    if \"RU\" not in idx or \"DC\" not in idx:\n",
    "        continue\n",
    "    # Columns should be years\n",
    "    years = [int(str(c).strip()) for c in df.columns]\n",
    "    rows.append(pd.DataFrame({\n",
    "        \"zone\": _norm(zname),\n",
    "        \"year\": years,\n",
    "        \"RU_share\": pd.to_numeric(df.loc[idx[\"RU\"]].values, errors=\"coerce\"),\n",
    "        \"DC_share\": pd.to_numeric(df.loc[idx[\"DC\"]].values, errors=\"coerce\"),\n",
    "    }))\n",
    "if not rows:\n",
    "    raise RuntimeError(\"No regions parsed from RU/DC workbook (Each sheet must contain RU/DC rows with years as columns).\")\n",
    "\n",
    "zone_shares = pd.concat(rows, ignore_index=True).fillna(0.0)\n",
    "zone_shares[\"zone\"] = zone_shares[\"zone\"].map(_norm)\n",
    "zone_shares[\"year\"] = zone_shares[\"year\"].astype(int)\n",
    "\n",
    "# ---------- 1) Read Project Table (Fixed C..AB for allocation columns) ----------\n",
    "proj = pd.read_excel(PATH_PROJECTS, sheet_name=SHEET_PROJECTS)\n",
    "\n",
    "# Column validation: Must have at least up to column AB\n",
    "if proj.shape[1] < ZONE_COL_SLICE.stop:\n",
    "    raise RuntimeError(f\"Insufficient columns in project table: Need at least {ZONE_COL_SLICE.stop} columns for C..AB allocation, but only found {proj.shape[1]}.\")\n",
    "\n",
    "owner_col = find_col(proj, [\"owner_mapped\", \"owner mapped\", \"owner\"])\n",
    "year_col  = find_col(proj, [\"year\", \"年份\"])\n",
    "cost_col  = find_col(proj, [\"teac_cost\", \"teac cost\", \"cost\", \"TEAC cost\"])\n",
    "\n",
    "proj = proj.copy()\n",
    "proj[owner_col] = proj[owner_col].astype(str).map(_norm)\n",
    "proj[\"year\"]    = pd.to_numeric(proj[year_col], errors=\"coerce\").astype(\"Int64\")\n",
    "proj[\"teac_cost\"] = pd.to_numeric(proj[cost_col], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# Attribution Scenario Columns (0/1), Conservative capture: Name contains DC_ATTR\n",
    "attr_cols = [c for c in proj.columns if \"DC_ATTR\" in str(c).upper()]\n",
    "if not attr_cols:\n",
    "    # Fallback: If no DC_ATTR_*, try to capture columns containing only 0/1\n",
    "    for c in proj.columns:\n",
    "        s = pd.to_numeric(proj[c], errors=\"coerce\").dropna()\n",
    "        if s.empty:\n",
    "            continue\n",
    "        if s.isin([0,1]).all():\n",
    "            attr_cols.append(c)\n",
    "if not attr_cols:\n",
    "    raise RuntimeError(\"No attribution scenario columns identified (DC_ATTR_* or all 0/1 columns).\")\n",
    "\n",
    "# —— Fixed Allocation Columns: C..AB ——\n",
    "zone_cols = list(proj.columns[ZONE_COL_SLICE])\n",
    "zone_map_from_col = {c: _norm(c) for c in zone_cols}\n",
    "\n",
    "# Full sets for zero-filling\n",
    "ALL_YEARS  = sorted(pd.to_numeric(proj[\"year\"].dropna()).astype(int).unique().tolist())\n",
    "ALL_ZONES  = sorted(set(zone_map_from_col.values()) | set(zone_shares[\"zone\"].unique()))\n",
    "ALL_OWNERS = sorted(proj[owner_col].dropna().unique().tolist())\n",
    "\n",
    "# Pad RU/DC shares with 0 for (zone, year)\n",
    "idx_sh = pd.MultiIndex.from_product([ALL_ZONES, ALL_YEARS], names=[\"zone\",\"year\"])\n",
    "zone_shares = (zone_shares.set_index([\"zone\",\"year\"])[[\"RU_share\",\"DC_share\"]]\n",
    "               .reindex(idx_sh, fill_value=0.0).reset_index())\n",
    "\n",
    "owner_tabs, zone_tabs, user_tabs, links1_tabs, links2_tabs, diag_tabs = [], [], [], [], [], []\n",
    "\n",
    "# ---------- 2) Main Process (Per Scenario) ----------\n",
    "for attr_col in attr_cols:\n",
    "    scenario = str(attr_col)\n",
    "\n",
    "    # Table B: Owner x Year Initial Cost (0/1 Attribution)\n",
    "    is_dc = pd.to_numeric(proj[attr_col], errors=\"coerce\").fillna(0).astype(int).clip(0,1).values\n",
    "    proj[\"cost_dc_attr_init\"] = proj[\"teac_cost\"] * (is_dc == 1)\n",
    "    proj[\"cost_non_dc_init\"]  = proj[\"teac_cost\"] * (is_dc == 0)\n",
    "\n",
    "    g = proj.groupby([owner_col, \"year\"], dropna=True)\n",
    "    owner_init = (g[[\"cost_dc_attr_init\",\"cost_non_dc_init\"]].sum()\n",
    "                    .rename(columns={\"cost_dc_attr_init\":\"cost_dc_attr\",\n",
    "                                     \"cost_non_dc_init\":\"cost_non_dc\"})\n",
    "                    .reset_index().rename(columns={owner_col:\"region\"}))\n",
    "\n",
    "    # Zero-fill full set (owner, year)\n",
    "    idx_oy = pd.MultiIndex.from_product([ALL_OWNERS, ALL_YEARS], names=[\"region\",\"year\"])\n",
    "    owner_init = (owner_init.set_index([\"region\",\"year\"])[[\"cost_dc_attr\",\"cost_non_dc\"]]\n",
    "                    .reindex(idx_oy, fill_value=0.0).reset_index())\n",
    "    owner_init[\"scenario\"] = scenario\n",
    "    owner_tabs.append(owner_init)\n",
    "\n",
    "    # Table C: Zone x Year Cost (Row-wise normalization + Cost * 0/1 * Weight; Aggregate first then merge to ensure conservation)\n",
    "    shares_raw = proj[zone_cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0.0).copy()\n",
    "\n",
    "    # Row-wise normalization (approx 100 treated as percentage; otherwise sum and normalize; keep 0 if sum is 0)\n",
    "    row_sum = shares_raw.sum(axis=1)\n",
    "    is_pct  = (row_sum >= 90.0) & (row_sum <= 110.0)          # Approx 100 -> Percentage\n",
    "    need_norm = (row_sum > 0) & (~np.isclose(row_sum, 1.0)) & (~is_pct)\n",
    "    norm_factor = pd.Series(1.0, index=shares_raw.index)\n",
    "    norm_factor[is_pct] = 100.0\n",
    "    norm_factor[need_norm] = row_sum[need_norm]\n",
    "    shares = shares_raw.div(norm_factor, axis=0).clip(lower=0.0)\n",
    "\n",
    "    # Row-level Conservation Check (Critical)\n",
    "    cost = proj[\"teac_cost\"].values\n",
    "    dc_alloc = shares.mul(cost * (is_dc == 1), axis=0)\n",
    "    nd_alloc = shares.mul(cost * (is_dc == 0), axis=0)\n",
    "    dc_row_err = np.abs(dc_alloc.sum(axis=1).values - cost * (is_dc == 1))\n",
    "    nd_row_err = np.abs(nd_alloc.sum(axis=1).values - cost * (is_dc == 0))\n",
    "    max_row_err = float(max(dc_row_err.max(initial=0.0), nd_row_err.max(initial=0.0)))\n",
    "\n",
    "    diag = pd.DataFrame({\n",
    "        \"scenario\": scenario,\n",
    "        \"row_index\": np.arange(len(proj)),\n",
    "        \"year\": proj[\"year\"].values,\n",
    "        \"teac_cost\": proj[\"teac_cost\"].values,\n",
    "        \"sum_before\": row_sum.values,\n",
    "        \"treated_as_percent\": is_pct.astype(int).values,\n",
    "        \"norm_factor\": norm_factor.values,\n",
    "        \"sum_after\": shares.sum(axis=1).values,\n",
    "        \"is_dc\": is_dc,\n",
    "        \"row_err\": (dc_row_err + nd_row_err)\n",
    "    })\n",
    "    diag_tabs.append(diag)\n",
    "\n",
    "    # Aggregate by year in wide format first, then melt, avoiding many-to-many amplification\n",
    "    dc_zone_year = sum_alloc_by_zone_year(dc_alloc, proj[\"year\"], zone_cols, zone_map_from_col, \"cost_dc_attr\")\n",
    "    nd_zone_year = sum_alloc_by_zone_year(nd_alloc, proj[\"year\"], zone_cols, zone_map_from_col, \"cost_non_dc\")\n",
    "    zone_year = dc_zone_year.merge(nd_zone_year, on=[\"zone\",\"year\"], how=\"outer\").fillna(0.0)\n",
    "\n",
    "    # Zero-fill full set (zone, year)\n",
    "    idx_zy = pd.MultiIndex.from_product([ALL_ZONES, ALL_YEARS], names=[\"zone\",\"year\"])\n",
    "    zone_year = (zone_year.set_index([\"zone\",\"year\"])[[\"cost_dc_attr\",\"cost_non_dc\"]]\n",
    "                    .reindex(idx_zy, fill_value=0.0).reset_index())\n",
    "    zone_year[\"scenario\"] = scenario\n",
    "    zone_tabs.append(zone_year)\n",
    "\n",
    "    # Annual Conservation Check (B vs C)\n",
    "    b_tot = owner_init.groupby(\"year\")[[\"cost_dc_attr\",\"cost_non_dc\"]].sum().sort_index()\n",
    "    c_tot = zone_year.groupby(\"year\")[[\"cost_dc_attr\",\"cost_non_dc\"]].sum().sort_index()\n",
    "    diff = (c_tot - b_tot).abs()\n",
    "    max_diff_year = float(diff.values.max()) if not diff.empty else 0.0\n",
    "    if max_diff_year > 1e-6:\n",
    "        print(f\"[WARN][{scenario}] B <-> C Annual Conservation Max Diff = {max_diff_year:.6f}\")\n",
    "\n",
    "    # Table D: Zone -> User (Allocated by final RU/DC shares)\n",
    "    zjoin = zone_year.merge(zone_shares, on=[\"zone\",\"year\"], how=\"left\", validate=\"m:1\").fillna(0.0)\n",
    "    zjoin[\"ru_from_dc_growth\"]  = zjoin[\"cost_dc_attr\"] * zjoin[\"RU_share\"]\n",
    "    zjoin[\"dc_from_dc_growth\"]  = zjoin[\"cost_dc_attr\"] * zjoin[\"DC_share\"]\n",
    "    zjoin[\"ru_from_non_dc\"]     = zjoin[\"cost_non_dc\"]  * zjoin[\"RU_share\"]\n",
    "    zjoin[\"dc_from_non_dc\"]     = zjoin[\"cost_non_dc\"]  * zjoin[\"DC_share\"]\n",
    "    zjoin[\"ru_total\"] = zjoin[\"ru_from_dc_growth\"] + zjoin[\"ru_from_non_dc\"]\n",
    "    zjoin[\"dc_total\"] = zjoin[\"dc_from_dc_growth\"] + zjoin[\"dc_from_non_dc\"]\n",
    "\n",
    "    user_tbl = zjoin[[\"zone\",\"year\",\n",
    "                      \"ru_from_dc_growth\",\"ru_from_non_dc\",\"ru_total\",\n",
    "                      \"dc_from_dc_growth\",\"dc_from_non_dc\",\"dc_total\"]].copy()\n",
    "    idx_uy = pd.MultiIndex.from_product([ALL_ZONES, ALL_YEARS], names=[\"zone\",\"year\"])\n",
    "    user_tbl = (user_tbl.set_index([\"zone\",\"year\"])\n",
    "                .reindex(idx_uy, fill_value=0.0).reset_index())\n",
    "    user_tbl[\"scenario\"] = scenario\n",
    "    user_tabs.append(user_tbl)\n",
    "\n",
    "    # Two-layer Sankey links\n",
    "    links1_tabs.append(pd.concat([\n",
    "        zone_year.assign(source=\"DC_growth\", target=zone_year[\"zone\"], value=zone_year[\"cost_dc_attr\"])[[\"year\",\"source\",\"target\",\"value\"]].assign(scenario=scenario),\n",
    "        zone_year.assign(source=\"NonDC\",     target=zone_year[\"zone\"], value=zone_year[\"cost_non_dc\"])[[\"year\",\"source\",\"target\",\"value\"]].assign(scenario=scenario),\n",
    "    ], ignore_index=True))\n",
    "    l2_ru = user_tbl.assign(source=user_tbl[\"zone\"], target=\"RU\", value=user_tbl[\"ru_total\"])[[\"year\",\"source\",\"target\",\"value\"]].assign(scenario=scenario)\n",
    "    l2_dc = user_tbl.assign(source=user_tbl[\"zone\"], target=\"DC\", value=user_tbl[\"dc_total\"])[[\"year\",\"source\",\"target\",\"value\"]].assign(scenario=scenario)\n",
    "    links2_tabs.append(pd.concat([l2_ru, l2_dc], ignore_index=True))\n",
    "\n",
    "# ---------- 3) Export ----------\n",
    "owner_all = pd.concat(owner_tabs,  ignore_index=True)\n",
    "zone_all  = pd.concat(zone_tabs,   ignore_index=True)\n",
    "user_all  = pd.concat(user_tabs,   ignore_index=True)\n",
    "links1_all= pd.concat(links1_tabs, ignore_index=True)\n",
    "links2_all= pd.concat(links2_tabs, ignore_index=True)\n",
    "diag_all  = pd.concat(diag_tabs,   ignore_index=True)\n",
    "\n",
    "# Meta info sheet, explicitly stating: Allocation columns used C..AB\n",
    "meta = pd.DataFrame({\n",
    "    \"key\": [\"n_rows_proj\",\"n_zone_cols\",\"zone_col_slice\",\"attr_cols\"],\n",
    "    \"value\": [len(proj), len(zone_cols), \"C..AB (pandas slice 2:28)\", str(attr_cols)]\n",
    "})\n",
    "\n",
    "with pd.ExcelWriter(OUT_PATH, engine=\"openpyxl\") as w:\n",
    "    owner_all.to_excel(w, index=False, sheet_name=\"B_owner_init_costs\")\n",
    "    zone_all.to_excel(w,  index=False, sheet_name=\"C_zone_alloc_costs\")\n",
    "    user_all.to_excel(w,  index=False, sheet_name=\"D_zone_user_costs\")\n",
    "    links1_all.to_excel(w,index=False, sheet_name=\"L1_links_src_to_zone\")\n",
    "    links2_all.to_excel(w,index=False, sheet_name=\"L2_links_zone_to_user\")\n",
    "    diag_all.to_excel(w, index=False, sheet_name=\"Diagnostics\")\n",
    "    meta.to_excel(w, index=False, sheet_name=\"Meta\")\n",
    "\n",
    "print(f\"Done! Saved to: {OUT_PATH.resolve()}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybkb",
   "language": "python",
   "name": "pybkb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
