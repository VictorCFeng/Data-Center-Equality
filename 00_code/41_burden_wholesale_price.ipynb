{
 "cells": [
  {
   "cell_type": "code",
   "id": "b7593c34325551f0",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ===================== Path Configuration (Modify as Needed) =====================\n",
    "PATH_MAP = Path(\"./poverty/county_to_iso_or_city.xlsx\")   # Figure 1: county_fips -> iso, zone mapping\n",
    "MAP_SHEET = 0                                             # Or sheet name\n",
    "DIR_LEAD_2022 = Path(\"./poverty/LEAD/\")                   # Figure 2: Directory containing \"AK AMI Counties 2022.csv\" etc.\n",
    "PATH_INCOME_GROWTH = Path(\"./poverty/macroeconomic.xlsx\")   # Figure 4: Income growth factors (Row where 2022=1)\n",
    "INCOME_SHEET = 0                                          # Or sheet name, script auto-searches for \"Real Dispos\" row\n",
    "DIR_ISO_PRICES = Path(\"./rider/\")                         # Figures 5-6: Several xlsx files (e.g., ERCOT_zone_prices.xlsx)\n",
    "PATH_GAS_OIL = Path(\"./poverty/fuel/state_fuel_price.xlsx\")  # Figure 7: Each sheet is a state, rows contain NG, DFO\n",
    "OUT_DIR = Path(\"./poverty/\")                              # Output directory (One xlsx per year)\n",
    "YEARS = list(range(2025, 2030 + 1))                       # Target Years\n",
    "# =============== Utility: State FIPS -> State Abbreviation (For matching LEAD rows to states) ===============\n",
    "STATE_FIPS_TO_ABBR = {\n",
    "    \"01\":\"AL\",\"02\":\"AK\",\"04\":\"AZ\",\"05\":\"AR\",\"06\":\"CA\",\"08\":\"CO\",\"09\":\"CT\",\"10\":\"DE\",\"11\":\"DC\",\"12\":\"FL\",\n",
    "    \"13\":\"GA\",\"15\":\"HI\",\"16\":\"ID\",\"17\":\"IL\",\"18\":\"IN\",\"19\":\"IA\",\"20\":\"KS\",\"21\":\"KY\",\"22\":\"LA\",\"23\":\"ME\",\n",
    "    \"24\":\"MD\",\"25\":\"MA\",\"26\":\"MI\",\"27\":\"MN\",\"28\":\"MS\",\"29\":\"MO\",\"30\":\"MT\",\"31\":\"NE\",\"32\":\"NV\",\"33\":\"NH\",\n",
    "    \"34\":\"NJ\",\"35\":\"NM\",\"36\":\"NY\",\"37\":\"NC\",\"38\":\"ND\",\"39\":\"OH\",\"40\":\"OK\",\"41\":\"OR\",\"42\":\"PA\",\"44\":\"RI\",\n",
    "    \"45\":\"SC\",\"46\":\"SD\",\"47\":\"TN\",\"48\":\"TX\",\"49\":\"UT\",\"50\":\"VT\",\"51\":\"VA\",\"53\":\"WA\",\"54\":\"WV\",\"55\":\"WI\",\n",
    "    \"56\":\"WY\",\"72\":\"PR\"}\n",
    "# ===================== General Cleaning Functions =====================\n",
    "def clean_zone(z: str, iso: str | None = None) -> str:\n",
    "    \"\"\"Remove prefix + remove punctuation + uppercase. E.g.: 'CAISO_ZP-26' -> 'ZP26'; 'MISO_LRZ8_' -> 'LRZ8'\"\"\"\n",
    "    if pd.isna(z) or z is None:\n",
    "        return \"\"\n",
    "    z0 = str(z).strip()\n",
    "    # Remove leading ISO prefix (PJM_, CAISO-, ERCOT_ etc.)\n",
    "    if iso and isinstance(iso, str) and len(iso) > 0:\n",
    "        pattern = r\"^\\s*{0}[\\s_\\-:/]+\".format(re.escape(iso))\n",
    "        z0 = re.sub(pattern, \"\", z0, flags=re.IGNORECASE)\n",
    "    # Remove all non-alphanumeric characters\n",
    "    z0 = re.sub(r\"[^A-Za-z0-9]+\", \"\", z0)\n",
    "    return z0.upper()\n",
    "\n",
    "def clean_iso_name_from_filename(p: Path) -> str:\n",
    "    \"\"\"Extract ISO name 'PJM' from 'PJM_zone_prices.xlsx'.\"\"\"\n",
    "    name = p.stem\n",
    "    m = re.match(r\"([A-Za-z\\-]+)\", name)\n",
    "    iso = m.group(1) if m else name\n",
    "    return iso.upper().replace(\"-\", \"\")\n",
    "\n",
    "# ===================== 1) Load Mapping Table =====================\n",
    "def load_county_map(path: Path, sheet=0) -> pd.DataFrame:\n",
    "    df = pd.read_excel(path, sheet_name=sheet, dtype={\"county_fips\": str})\n",
    "    # Keep only necessary columns\n",
    "    need_cols = [\"county_fips\", \"iso\", \"zone\"]\n",
    "    miss = [c for c in need_cols if c not in df.columns]\n",
    "    if miss:\n",
    "        raise ValueError(f\"Mapping table missing columns: {miss}\")\n",
    "    df[\"county_fips\"] = df[\"county_fips\"].astype(str).str.zfill(5)\n",
    "    df[\"iso\"] = df[\"iso\"].astype(str).str.strip().str.upper()\n",
    "    # Zone cleaning (Don't remove prefix yet, as ISO varies; clean per county later)\n",
    "    return df[need_cols]\n",
    "\n",
    "# ===================== 2) Aggregate LEAD 2022 Baseline =====================\n",
    "def load_lead_2022(dir_path: Path) -> pd.DataFrame:\n",
    "    records = []\n",
    "    for csv in sorted(dir_path.glob(\"* AMI Counties 2022.csv\")):\n",
    "        try:\n",
    "            df = pd.read_csv(csv, low_memory=False)\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(csv, low_memory=False, encoding=\"latin1\")\n",
    "\n",
    "        df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "        need_val = [\"HINCP*UNITS\",\"ELEP*UNITS\",\"GASP*UNITS\",\"FULP*UNITS\"]\n",
    "        for c in need_val:\n",
    "            if c not in df.columns:\n",
    "                raise KeyError(f\"{c} missing in {csv.name}\")\n",
    "\n",
    "        units_col = \"UNITS\" if \"UNITS\" in df.columns else (\"FREQUENCY\" if \"FREQUENCY\" in df.columns else None)\n",
    "        if units_col is None:\n",
    "            raise KeyError(f\"Neither UNITS nor FREQUENCY found: {csv.name}\")\n",
    "        seg_candidates = [\"AMI150\",\"TEN\",\"TEN-YBL6\",\"TEN-BLD\",\"TEN-HFL\",\"NAME\"]\n",
    "        seg_cols = [c for c in seg_candidates if c in df.columns]\n",
    "\n",
    "        if \"FIP\" not in df.columns:\n",
    "            raise KeyError(f\"FIP missing in {csv.name}\")\n",
    "        df[\"county_fips\"] = df[\"FIP\"].astype(str).str.zfill(5)\n",
    "        df[\"state_abbr\"]  = df[\"county_fips\"].str[:2].map(STATE_FIPS_TO_ABBR)\n",
    "        cols = [\"county_fips\",\"state_abbr\", units_col] + seg_cols + need_val\n",
    "        tmp = df[cols].copy()\n",
    "        tmp = tmp.rename(columns={units_col: \"UNITS\"})\n",
    "        tmp[\"UNITS\"] = pd.to_numeric(tmp[\"UNITS\"], errors=\"coerce\").fillna(0.0)\n",
    "        for c in need_val:\n",
    "            tmp[c] = pd.to_numeric(tmp[c], errors=\"coerce\").fillna(0.0)\n",
    "        records.append(tmp)\n",
    "\n",
    "    lead = pd.concat(records, ignore_index=True)\n",
    "    return lead\n",
    "\n",
    "# ===================== 3) Income Growth Factors (2022=1) =====================\n",
    "def load_income_growth(path: Path, sheet=0, years: List[int] = YEARS) -> Dict[int, float]:\n",
    "    df = pd.read_excel(path, sheet_name=sheet)\n",
    "    row_idx = None\n",
    "    if df.columns.size >= 2:\n",
    "        first_col = df.columns[0]\n",
    "        mask = df[first_col].astype(str).str.contains(\"Real Dispos\", case=False, na=False)\n",
    "        if mask.any():\n",
    "            row_idx = df[mask].index[-1]\n",
    "    if row_idx is None:\n",
    "        row_idx = df.dropna(how=\"all\", axis=0).index[-1]\n",
    "    row = df.loc[row_idx]\n",
    "    growth = {}\n",
    "    for y in years + [2022]:\n",
    "        if y in df.columns:\n",
    "            growth[y] = float(row[y])\n",
    "        else:\n",
    "            # Error if column missing\n",
    "            raise KeyError(f\"Income growth table missing year column {y}\")\n",
    "    if abs(growth[2022] - 1.0) > 1e-6:\n",
    "        # Normalize to 2022=1 if not already\n",
    "        base = growth[2022]\n",
    "        for k in list(growth.keys()):\n",
    "            growth[k] = growth[k] / base\n",
    "    # Return only target years\n",
    "    return {y: growth[y] for y in years}\n",
    "\n",
    "# ===================== 4) ISO Price Ratios (vs 2022) =====================\n",
    "def load_iso_price_ratios(dir_path: Path, years: list[int]) -> dict:\n",
    "    import re, numpy as np, pandas as pd, openpyxl\n",
    "\n",
    "    def _clean_zone(z: str, iso: str | None = None) -> str:\n",
    "        if z is None or (isinstance(z, float) and pd.isna(z)):\n",
    "            return \"\"\n",
    "        s = str(z).strip()\n",
    "        if iso:\n",
    "            s = re.sub(rf\"^\\s*{re.escape(iso)}[\\s_\\-:/]+\", \"\", s, flags=re.IGNORECASE)\n",
    "        s = re.sub(r\"[^A-Za-z0-9]+\", \"\", s)\n",
    "        return s.upper()\n",
    "\n",
    "    def _iso_from_filename(p: Path) -> str:\n",
    "        return re.sub(r\"[^A-Za-z]\", \"\", p.stem.split(\"_\")[0]).upper()\n",
    "\n",
    "    def _coerce_year_cols_to_int(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        mapper = {}\n",
    "        for c in df.columns:\n",
    "            cs = str(c).strip()\n",
    "            if re.fullmatch(r\"\\d{4}\", cs):\n",
    "                mapper[c] = int(cs)\n",
    "        return df.rename(columns=mapper)\n",
    "\n",
    "    def _read_sheet_pandas(xlsx: Path, sheet: str) -> pd.DataFrame | None:\n",
    "        try:\n",
    "            return pd.read_excel(xlsx, sheet_name=sheet, engine=\"openpyxl\")\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def _read_sheet_openpyxl_data_only(xlsx: Path, sheet: str) -> pd.DataFrame | None:\n",
    "        try:\n",
    "            wb = openpyxl.load_workbook(xlsx, data_only=True, read_only=True)\n",
    "            if sheet not in wb.sheetnames:\n",
    "                return None\n",
    "            ws = wb[sheet]\n",
    "            data = list(ws.values)\n",
    "            if not data:\n",
    "                return None\n",
    "            return pd.DataFrame(data[1:], columns=data[0])\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def _numeric_series(s: pd.Series) -> pd.Series:\n",
    "        s = s.copy()\n",
    "        new_idx = []\n",
    "        for k in s.index:\n",
    "            ks = str(k).strip()\n",
    "            if re.fullmatch(r\"\\d{4}\", ks):\n",
    "                new_idx.append(int(ks))\n",
    "            else:\n",
    "                new_idx.append(k)\n",
    "        s.index = new_idx\n",
    "        for k in list(s.index):\n",
    "            if isinstance(k, int) and 2000 <= k <= 2100:\n",
    "                s.loc[k] = pd.to_numeric(s.loc[k], errors=\"coerce\")\n",
    "        return s\n",
    "\n",
    "    def _pick_row(df_idxed: pd.DataFrame, names: list[str]) -> pd.Series | None:\n",
    "        for nm in names:\n",
    "            if nm in df_idxed.index:\n",
    "                return df_idxed.loc[nm]\n",
    "        for nm in names:\n",
    "            m = df_idxed.index.to_series().str.contains(re.escape(nm), case=False, na=False)\n",
    "            if m.any():\n",
    "                return df_idxed.loc[m].iloc[0]\n",
    "        return None\n",
    "\n",
    "    def _get_year_val(s: pd.Series, y: int) -> float | None:\n",
    "        v = s.get(y, s.get(str(y), np.nan))\n",
    "        return float(v) if pd.notna(v) else None\n",
    "\n",
    "    ratios: dict = {}\n",
    "\n",
    "    for xlsx in sorted(dir_path.glob(\"*_zone_prices.xlsx\")):\n",
    "        iso = _iso_from_filename(xlsx)\n",
    "        ratios.setdefault(iso, {})\n",
    "        try:\n",
    "            sheets = pd.ExcelFile(xlsx).sheet_names\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        for sheet in sheets:\n",
    "            # --- Correction: Explicit None check, no longer using 'or' to chain DataFrames ---\n",
    "            df = _read_sheet_pandas(xlsx, sheet)\n",
    "            if df is None or df.empty:\n",
    "                df = _read_sheet_openpyxl_data_only(xlsx, sheet)\n",
    "            if df is None or df.empty:\n",
    "                continue\n",
    "\n",
    "            df = _coerce_year_cols_to_int(df)\n",
    "            # Find item column; fallback to first column\n",
    "            item_col = None\n",
    "            for c in df.columns:\n",
    "                if str(c).strip().lower() == \"item\":\n",
    "                    item_col = c\n",
    "                    break\n",
    "            if item_col is None:\n",
    "                item_col = df.columns[0]\n",
    "            df[item_col] = df[item_col].astype(str).str.strip().str.lower()\n",
    "            df = df.set_index(item_col)\n",
    "\n",
    "            s_total  = _pick_row(df, [\"total\"])\n",
    "            s_minus  = _pick_row(df, [\"total_minus_dc\", \"total minus dc\", \"total_minus_dc \"])\n",
    "            s_gshare = _pick_row(df, [\"gen_share (=gen/total)\", \"gen_share\", \"gen share\"])\n",
    "            s_dc     = _pick_row(df, [\"dc_cumulate\", \"dc_cumulative\", \"dc cumulate\"])\n",
    "            if s_total is None:\n",
    "                continue\n",
    "\n",
    "            s_total = _numeric_series(s_total)\n",
    "            if s_minus is not None:\n",
    "                s_minus = _numeric_series(s_minus)\n",
    "            if s_gshare is not None:\n",
    "                s_gshare = _numeric_series(s_gshare)\n",
    "            if s_dc is not None:\n",
    "                s_dc = _numeric_series(s_dc)\n",
    "\n",
    "            # Rebuild if total_minus_dc missing/NaN\n",
    "            need_rebuild = (s_minus is None) or (s_minus.dropna().empty) or pd.isna(s_minus.iloc[0])\n",
    "            if need_rebuild:\n",
    "                df2 = _read_sheet_openpyxl_data_only(xlsx, sheet)\n",
    "                if df2 is not None and not df2.empty:\n",
    "                    df2 = _coerce_year_cols_to_int(df2)\n",
    "                    if item_col in df2.columns:\n",
    "                        df2[item_col] = df2[item_col].astype(str).str.strip().str.lower()\n",
    "                        df2 = df2.set_index(item_col)\n",
    "                        s2 = _pick_row(df2, [\"total_minus_dc\", \"total minus dc\", \"total_minus_dc \"])\n",
    "                        if s2 is not None:\n",
    "                            s_minus = _numeric_series(s2)\n",
    "\n",
    "            if (s_minus is None) or (s_minus.dropna().empty) or pd.isna(s_minus.iloc[0]):\n",
    "                if (s_gshare is not None) and (s_dc is not None) and (not s_total.dropna().empty):\n",
    "                    s_minus = s_total - s_dc\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            # Base year (first column assumed 2022)\n",
    "            try:\n",
    "                base_total = float(s_total.iloc[0])\n",
    "            except Exception:\n",
    "                continue\n",
    "            if base_total == 0 or not np.isfinite(base_total):\n",
    "                continue\n",
    "\n",
    "            zone_clean = _clean_zone(sheet, iso)\n",
    "            if not zone_clean:\n",
    "                continue\n",
    "\n",
    "            for y in years:\n",
    "                v_tot = _get_year_val(s_total, y)\n",
    "                v_min = _get_year_val(s_minus, y)\n",
    "                if v_tot is None or v_min is None or not np.isfinite(v_tot) or not np.isfinite(v_min):\n",
    "                    continue\n",
    "                r_with = float(v_tot) / base_total\n",
    "                r_no   = float(v_min) / base_total\n",
    "                ratios[iso].setdefault(zone_clean, {})\n",
    "                ratios[iso][zone_clean][f\"with_dc_{y}\"] = r_with\n",
    "                ratios[iso][zone_clean][f\"no_dc_{y}\"]   = r_no\n",
    "\n",
    "    return ratios\n",
    "\n",
    "# ===================== 5) State Fuel Price Ratios (vs 2022) =====================\n",
    "def load_state_fuel_price_ratios(path: Path, years: List[int] = YEARS) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns two DataFrames: gas_ratio[STATE_ABBR, year], oil_ratio[STATE_ABBR, year]\n",
    "    Based on 'NG (Natural Gas)' and 'DFO (Distillate Fuel Oil)' rows.\n",
    "    \"\"\"\n",
    "    gas_ratios = {}\n",
    "    oil_ratios = {}\n",
    "    xls = pd.ExcelFile(path)\n",
    "    for sheet in xls.sheet_names:\n",
    "        df = pd.read_excel(path, sheet_name=sheet)\n",
    "        # Row name in first column\n",
    "        idx_col = df.columns[0]\n",
    "        df[idx_col] = df[idx_col].astype(str).str.strip()\n",
    "        df = df.set_index(idx_col)\n",
    "        def pick_row_exact(cand: List[str]) -> pd.Series | None:\n",
    "            for nm in cand:\n",
    "                if nm in df.index:\n",
    "                    return df.loc[nm]\n",
    "            # Fuzzy match fallback\n",
    "            for nm in cand:\n",
    "                m = df.index.to_series().str.contains(re.escape(nm), case=False, na=False)\n",
    "                if m.any():\n",
    "                    return df.loc[m].iloc[0]\n",
    "            return None\n",
    "        s_ng  = pick_row_exact([\"NG (Natural Gas)\", \"Natural Gas\"])\n",
    "        s_dfo = pick_row_exact([\"DFO (Distillate Fuel Oil)\", \"Distillate Fuel Oil\"])\n",
    "        if s_ng is None or s_dfo is None:\n",
    "            continue\n",
    "        base_ng  = float(s_ng[2022])\n",
    "        base_dfo = float(s_dfo[2022])\n",
    "        if base_ng == 0 or base_dfo == 0:\n",
    "            continue\n",
    "        gas_ratios[sheet] = {y: float(s_ng[y]) / base_ng for y in years if y in s_ng.index}\n",
    "        oil_ratios[sheet] = {y: float(s_dfo[y]) / base_dfo for y in years if y in s_dfo.index}\n",
    "    gas_df = pd.DataFrame.from_dict(gas_ratios, orient=\"index\").sort_index()\n",
    "    oil_df = pd.DataFrame.from_dict(oil_ratios, orient=\"index\").sort_index()\n",
    "    gas_df.index.name = \"state_abbr\"\n",
    "    oil_df.index.name = \"state_abbr\"\n",
    "    return gas_df, oil_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# 0. Mapping Table\n",
    "m = load_county_map(PATH_MAP, MAP_SHEET)\n",
    "# ISOs with price tables\n",
    "iso_price_files = list(DIR_ISO_PRICES.glob(\"*_zone_prices.xlsx\"))\n",
    "iso_valid = set(clean_iso_name_from_filename(p) for p in iso_price_files)\n",
    "# Filter: Discard counties with no ISO or ISO not in price tables\n",
    "m = m[m[\"iso\"].isin(iso_valid)].copy()"
   ],
   "id": "9823ac975022435",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lead = load_lead_2022(DIR_LEAD_2022)\n",
    "base = lead.merge(m, on=\"county_fips\", how=\"inner\")\n",
    "income_growth = load_income_growth(PATH_INCOME_GROWTH, INCOME_SHEET, YEARS)"
   ],
   "id": "b219c759502a9ca9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "price_ratios = load_iso_price_ratios(DIR_ISO_PRICES, YEARS)\n",
    "gas_ratio_df, oil_ratio_df = load_state_fuel_price_ratios(PATH_GAS_OIL, YEARS)"
   ],
   "id": "440eef2d798449c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def split_and_clean_zones(series_zones, iso):\n",
    "    tokens = []\n",
    "    for z in series_zones.astype(str):\n",
    "        # Allow spaces: \"A | B\"\n",
    "        parts = re.split(r\"\\s*\\|\\s*\", z)\n",
    "        for p in parts:\n",
    "            if p and p.lower() != \"nan\":\n",
    "                tokens.append(clean_zone(p, iso))\n",
    "    # Deduplicate and remove empty\n",
    "    return sorted({t for t in tokens if t})"
   ],
   "id": "8c4ff072492df09a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_by_year = {y: [] for y in YEARS}\n",
    "n_counties = base[\"county_fips\"].nunique()\n",
    "rows_appended = 0\n",
    "skipped_no_zone = 0\n",
    "\n",
    "pbar = tqdm(base.groupby(\"county_fips\", sort=False), total=n_counties, desc=\"Processing counties\", leave=True)\n",
    "skipped_examples = []\n",
    "for county, g in pbar:\n",
    "    iso = g[\"iso\"].iloc[0]\n",
    "    state_abbr = g[\"state_abbr\"].iloc[0]\n",
    "\n",
    "    # Zones for this county (clean + deduplicate)\n",
    "    zones = split_and_clean_zones(g[\"zone\"], iso)\n",
    "    zone_ratios = [price_ratios.get(iso, {}).get(z, None) for z in zones]\n",
    "    zone_ratios = [r for r in zone_ratios if r]\n",
    "    if not zone_ratios:\n",
    "        skipped_no_zone += 1\n",
    "        skipped_examples.append({\n",
    "            \"county_fips\": county, \"iso\": iso, \"zones_raw\": list(g[\"zone\"].astype(str)),\n",
    "            \"zones_clean\": zones})\n",
    "        try:\n",
    "            pbar.set_postfix(rows=rows_appended, skipped_no_zone=skipped_no_zone)\n",
    "        except Exception:\n",
    "            pass\n",
    "        continue\n",
    "\n",
    "    def avg_ratio(key: str, year: int):\n",
    "        vals = [r.get(f\"{key}_{year}\") for r in zone_ratios if r.get(f\"{key}_{year}\") is not None]\n",
    "        return float(np.mean(vals)) if vals else None\n",
    "\n",
    "    # Segmentation columns (keep whichever exist)\n",
    "    seg_cols = [c for c in [\"AMI150\",\"TEN\",\"TEN-YBL6\",\"TEN-BLD\",\"TEN-HFL\",\"NAME\"] if c in g.columns]\n",
    "\n",
    "    for _, row in g.iterrows():\n",
    "        inc0  = float(row[\"HINCP*UNITS\"])\n",
    "        elec0 = float(row[\"ELEP*UNITS\"])\n",
    "        gas0  = float(row[\"GASP*UNITS\"])\n",
    "        fuel0 = float(row[\"FULP*UNITS\"])\n",
    "\n",
    "        for y in YEARS:\n",
    "            r_with = avg_ratio(\"with_dc\", y)\n",
    "            r_no   = avg_ratio(\"no_dc\", y)\n",
    "            if r_with is None or r_no is None:\n",
    "                continue\n",
    "\n",
    "            income = inc0 * float(income_growth[y])\n",
    "            elec_with = elec0 * r_with\n",
    "            elec_no   = elec0 * r_no\n",
    "\n",
    "            try:\n",
    "                gas_ratio = float(gas_ratio_df.loc[state_abbr, y])\n",
    "                oil_ratio = float(oil_ratio_df.loc[state_abbr, y])\n",
    "            except Exception:\n",
    "                continue\n",
    "            gas_cost  = gas0  * gas_ratio\n",
    "            fuel_cost = fuel0 * oil_ratio\n",
    "\n",
    "            if income <= 0:\n",
    "                burden_with = np.nan\n",
    "                burden_no   = np.nan\n",
    "            else:\n",
    "                burden_with = 100.0 * (elec_with + gas_cost + fuel_cost) / income\n",
    "                burden_no   = 100.0 * (elec_no   + gas_cost + fuel_cost) / income\n",
    "\n",
    "            out_row = {\n",
    "                \"county_fips\": county,\n",
    "                \"iso\": iso,\n",
    "                \"zone_list\": \";\".join(zones),\n",
    "                \"state\": state_abbr,\n",
    "                \"UNITS\": float(row[\"UNITS\"]),\n",
    "                \"income_total\": income,\n",
    "                \"elec_with_dc\": elec_with,\n",
    "                \"elec_no_dc\":   elec_no,\n",
    "                \"gas\":  gas_cost,\n",
    "                \"fuel\": fuel_cost,\n",
    "                \"energy_burden_with_dc_%\": burden_with,\n",
    "                \"energy_burden_no_dc_%\":   burden_no,\n",
    "            }\n",
    "            for c in seg_cols:\n",
    "                out_row[c] = row[c]\n",
    "\n",
    "            results_by_year[y].append(out_row)\n",
    "            rows_appended += 1\n",
    "\n",
    "    # Update pbar stats\n",
    "    try:\n",
    "        pbar.set_postfix(rows=rows_appended, skipped_no_zone=skipped_no_zone)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Optional: Print summary\n",
    "print(f\"Done. counties={n_counties}, skipped_no_zone={skipped_no_zone}, rows_appended={rows_appended}\")\n",
    "\n"
   ],
   "id": "6ea5b8e417c0ac28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "from math import ceil\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    def tqdm(x, **k): return x\n",
    "\n",
    "CSV_CHUNK_ROWS = 2_000_000   # Chunk size for writing huge tables (adjustable)\n",
    "\n",
    "# 5) Output CSVs (One per Year)\n",
    "for y in YEARS:\n",
    "    dfy = pd.DataFrame(results_by_year[y])\n",
    "    if dfy.empty:\n",
    "        continue\n",
    "\n",
    "    out_csv = OUT_DIR / f\"energy_burden_{y}.csv\"\n",
    "    n = len(dfy)\n",
    "\n",
    "    if n <= CSV_CHUNK_ROWS:\n",
    "        # Standard Write\n",
    "        dfy.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    else:\n",
    "        # Stream Write (Low Memory/IO pressure)\n",
    "        it = tqdm(range(0, n, CSV_CHUNK_ROWS), desc=f\"Writing CSV {y}\")\n",
    "        first = True\n",
    "        for s in it:\n",
    "            e = min(s + CSV_CHUNK_ROWS, n)\n",
    "            dfy.iloc[s:e].to_csv(\n",
    "                out_csv,\n",
    "                mode=\"w\" if first else \"a\",\n",
    "                header=first,\n",
    "                index=False,\n",
    "                encoding=\"utf-8-sig\",\n",
    "            )\n",
    "            first = False\n",
    "\n",
    "print(f\"Done! CSVs written to: {OUT_DIR.resolve()}\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybkb",
   "language": "python",
   "name": "pybkb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
