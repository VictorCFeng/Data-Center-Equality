{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from __future__ import annotations\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============ Path Configuration (Modify as needed) ============\n",
    "DIR_YEARLY = Path(\"./poverty\")         # Directory where energy_burden_YYYY.csv was saved in the previous step\n",
    "DIR_LEAD_2022 = Path(\"./poverty/LEAD\") # Directory containing \"AK AMI Counties 2022.csv\" etc.\n",
    "OUT_DIR = Path(\"./energy_poverty_outputs\")  # Output directory for this script\n",
    "YEARS = list(range(2025, 2030 + 1))\n",
    "\n",
    "# Columns potentially used for LEAD segmentation (same names on both sides, missing filled with 'NA')\n",
    "SEG_COLS: List[str] = [\"AMI150\", \"TEN\", \"TEN-YBL6\", \"TEN-BLD\", \"TEN-HFL\", \"NAME\"]\n",
    "\n",
    "# ============ Utility Functions ============\n",
    "def ensure_cols_and_key(df: pd.DataFrame, seg_cols=SEG_COLS) -> pd.DataFrame:\n",
    "    \"\"\"Ensure segment columns exist, standardize as strings, fill missing with 'NA', and construct seg_key for alignment.\"\"\"\n",
    "    for c in seg_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "        # Standardize as string keys; set NaN to 'NA'\n",
    "        df[c] = df[c].astype(str)\n",
    "        df.loc[df[c].str.lower().isin([\"nan\", \"none\", \"null\", \"\"]), c] = \"NA\"\n",
    "    # Generate stable key (joined by '||' to avoid conflict with actual values)\n",
    "    df[\"seg_key\"] = df[seg_cols].agg(\"||\".join, axis=1)\n",
    "    return df\n",
    "\n",
    "def load_lead_units(dir_lead: Path) -> pd.DataFrame:\n",
    "    \"\"\"Aggregate LEAD 2022 for all states, extracting county_fips + segments + UNITS.\"\"\"\n",
    "    rows = []\n",
    "    for csv in sorted(dir_lead.glob(\"* AMI Counties 2022.csv\")):\n",
    "        try:\n",
    "            t = pd.read_csv(csv, low_memory=False)\n",
    "        except UnicodeDecodeError:\n",
    "            t = pd.read_csv(csv, low_memory=False, encoding=\"latin1\")\n",
    "        t.columns = [c.strip() for c in t.columns]\n",
    "        if \"FIP\" not in t.columns or \"UNITS\" not in t.columns:\n",
    "            continue\n",
    "        keep = [\"FIP\", \"UNITS\"] + [c for c in SEG_COLS if c in t.columns]\n",
    "        t = t[keep].copy()\n",
    "        t[\"county_fips\"] = t[\"FIP\"].astype(str).str.zfill(5)\n",
    "        t.rename(columns={\"UNITS\": \"units\"}, inplace=True)\n",
    "        t = ensure_cols_and_key(t)\n",
    "        rows.append(t[[\"county_fips\", \"units\", \"seg_key\"] + SEG_COLS])\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"No state files read from LEAD directory or missing FIP/UNITS columns.\")\n",
    "    units = pd.concat(rows, ignore_index=True)\n",
    "    # Convert to numeric\n",
    "    units[\"units\"] = pd.to_numeric(units[\"units\"], errors=\"coerce\").fillna(0.0)\n",
    "    return units\n",
    "\n",
    "def compute_poverty_shares(df_year: pd.DataFrame, units_ref: pd.DataFrame, year: int) -> pd.DataFrame:\n",
    "\n",
    "    df = df_year.copy()\n",
    "    df[\"county_fips\"] = df[\"county_fips\"].astype(str).str.zfill(5)\n",
    "    df = ensure_cols_and_key(df)\n",
    "    need_cols = [\n",
    "        \"county_fips\", \"iso\", \"seg_key\",\n",
    "        \"energy_burden_with_dc_%\", \"energy_burden_no_dc_%\"\n",
    "    ] + SEG_COLS\n",
    "    df = df[[c for c in need_cols if c in df.columns]].copy()\n",
    "\n",
    "    # Merge UNITS (household count weight)\n",
    "    merged = df.merge(\n",
    "        units_ref[[\"county_fips\", \"seg_key\", \"units\"]],\n",
    "        on=[\"county_fips\", \"seg_key\"],\n",
    "        how=\"left\",\n",
    "        validate=\"m:1\"\n",
    "    )\n",
    "\n",
    "    # Convert to numeric\n",
    "    merged[\"units\"] = pd.to_numeric(merged[\"units\"], errors=\"coerce\").fillna(0.0)\n",
    "    for c in [\"energy_burden_with_dc_%\", \"energy_burden_no_dc_%\"]:\n",
    "        merged[c] = pd.to_numeric(merged[c], errors=\"coerce\")\n",
    "\n",
    "    # ===== Exception and Missing Value Exclusion Rules =====\n",
    "    # 1) Units must be > 0\n",
    "    mask_units = merged[\"units\"] > 0\n",
    "    # 2) At least one scenario has a valid percentage (avoid counting if both are NaN)\n",
    "    mask_has_burden = merged[\"energy_burden_with_dc_%\"].notna() | merged[\"energy_burden_no_dc_%\"].notna()\n",
    "    # 3) Percentage > 100% in any scenario is considered anomalous, exclude entire row\n",
    "    mask_anomaly = (merged[\"energy_burden_with_dc_%\"] > 100) | (merged[\"energy_burden_no_dc_%\"] > 100)\n",
    "\n",
    "    valid = merged[mask_units & mask_has_burden & (~mask_anomaly)].copy()\n",
    "\n",
    "    out_rows = []\n",
    "    for county, g in valid.groupby(\"county_fips\", sort=False):\n",
    "        total_units = g[\"units\"].sum()\n",
    "        if total_units <= 0:\n",
    "            continue\n",
    "        # Threshold determination (percentage units)\n",
    "        gt6_with = g.loc[g[\"energy_burden_with_dc_%\"] > 6, \"units\"].sum()\n",
    "        gt10_with = g.loc[g[\"energy_burden_with_dc_%\"] > 10, \"units\"].sum()\n",
    "        gt6_no = g.loc[g[\"energy_burden_no_dc_%\"] > 6, \"units\"].sum()\n",
    "        gt10_no = g.loc[g[\"energy_burden_no_dc_%\"] > 10, \"units\"].sum()\n",
    "\n",
    "        share_with_dc_gt6 = float(gt6_with / total_units)\n",
    "        share_with_dc_gt10 = float(gt10_with / total_units)\n",
    "        share_no_dc_gt6 = float(gt6_no / total_units)\n",
    "        share_no_dc_gt10 = float(gt10_no / total_units)\n",
    "\n",
    "        # ISO for this county (take first non-null)\n",
    "        iso = g[\"iso\"].dropna().astype(str).iloc[0] if \"iso\" in g.columns and g[\"iso\"].notna().any() else \"\"\n",
    "\n",
    "        out_rows.append({\n",
    "            \"county_fips\": county,\n",
    "            \"iso\": iso,\n",
    "            \"year\": year,\n",
    "            \"total_units_counted\": float(total_units),\n",
    "\n",
    "            \"share_with_dc_gt6\": share_with_dc_gt6,\n",
    "            \"share_with_dc_gt10\": share_with_dc_gt10,\n",
    "            \"share_no_dc_gt6\": share_no_dc_gt6,\n",
    "            \"share_no_dc_gt10\": share_no_dc_gt10,\n",
    "\n",
    "            # Add two columns: Difference in share (with - no)\n",
    "            \"share_diff_gt6\": share_with_dc_gt6 - share_no_dc_gt6,\n",
    "            \"share_diff_gt10\": share_with_dc_gt10 - share_no_dc_gt10,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "\n",
    "# ============ Main Process ============\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Read LEAD UNITS (once)\n",
    "units_ref = load_lead_units(DIR_LEAD_2022)\n",
    "\n",
    "# 2) Process by year\n",
    "for y in YEARS:\n",
    "    in_csv = DIR_YEARLY / f\"energy_burden_{y}.csv\"\n",
    "    if not in_csv.exists():\n",
    "        print(f\"[Skip] Previous output not found: {in_csv}\")\n",
    "        continue\n",
    "    dfy = pd.read_csv(in_csv, low_memory=False)\n",
    "    res = compute_poverty_shares(dfy, units_ref, y)\n",
    "    if res.empty:\n",
    "        print(f\"[Warning] No valid records for year {y} (data might be filtered out).\")\n",
    "        continue\n",
    "    out_csv = OUT_DIR / f\"energy_poverty_share_{y}.csv\"\n",
    "    res.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[OK] {y} -> {out_csv}\")\n",
    "\n",
    "# 3) Optional: Merge into one master table\n",
    "parts = []\n",
    "for y in YEARS:\n",
    "    p = OUT_DIR / f\"energy_poverty_share_{y}.csv\"\n",
    "    if p.exists():\n",
    "        t = pd.read_csv(p, low_memory=False)\n",
    "        parts.append(t)\n",
    "if parts:\n",
    "    big = pd.concat(parts, ignore_index=True)\n",
    "    big.to_csv(OUT_DIR / \"energy_poverty_share_2025_2030_all_years.csv\",\n",
    "               index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[OK] Merged master table: {(OUT_DIR / 'energy_poverty_share_2025_2030_all_years.csv').resolve()}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybkb",
   "language": "python",
   "name": "pybkb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
